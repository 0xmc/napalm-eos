{"included": [{"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_get_bgp_neighbors[normal]", "teardown": {"duration": 5.507469177246094e-05, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.00031304359436035156, "outcome": "passed", "name": "setup"}, "run_index": 15, "call": {"duration": 0.0034770965576171875, "outcome": "passed", "name": "call"}, "duration": 0.0041582584381103516, "outcome": "passed"}, "type": "test", "id": 1}, {"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_get_optics[test_case0]", "teardown": {"duration": 7.295608520507812e-05, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.0001938343048095703, "outcome": "skipped", "name": "setup", "longrepr": "('/Users/dbarroso/.virtualenvs/napalm/lib/python2.7/site-packages/_pytest/python.py', 1419, u'Skipped: got empty parameter set, function test_get_optics at /Users/dbarroso/workspace/napalm/napalm-base/napalm_base/test/getters.py:52')"}, "run_index": 20, "duration": 0.00046062469482421875, "outcome": "skipped"}, "type": "test", "id": 2}, {"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_get_interfaces_ip[normal]", "teardown": {"duration": 7.605552673339844e-05, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.00026297569274902344, "outcome": "passed", "name": "setup"}, "run_index": 18, "call": {"duration": 0.0010950565338134766, "outcome": "passed", "name": "call"}, "duration": 0.0016970634460449219, "outcome": "passed"}, "type": "test", "id": 3}, {"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_get_lldp_neighbors_detail[normal]", "teardown": {"duration": 8.797645568847656e-05, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.00028896331787109375, "outcome": "passed", "name": "setup"}, "run_index": 2, "call": {"duration": 0.07482600212097168, "outcome": "failed", "name": "call", "longrepr": "cls = <test_getters.TestGetter instance at 0x105176ea8>, test_case = 'normal'\n\n    @functools.wraps(func)\n    def wrapper(cls, test_case):\n        cls.device.device.current_test = func.__name__\n        cls.device.device.current_test_case = test_case\n    \n        try:\n>           result = func(cls)\n\n../napalm-base/napalm_base/test/getters.py:59: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <test_getters.TestGetter instance at 0x105176ea8>\n\n    @wrap_test_cases\n    def test_get_lldp_neighbors_detail(self):\n        \"\"\"Test get_lldp_neighbors_detail.\"\"\"\n        get_lldp_neighbors_detail = self.device.get_lldp_neighbors_detail()\n        result = len(get_lldp_neighbors_detail) > 0\n    \n        for interface, neighbor_list in get_lldp_neighbors_detail.iteritems():\n            for neighbor in neighbor_list:\n                result = result and helpers.test_model(models.lldp_neighbors_detail, neighbor)\n    \n>       assert result\nE       assert False\n\n../napalm-base/napalm_base/test/getters.py:188: AssertionError"}, "duration": 0.07549190521240234, "outcome": "failed"}, "type": "test", "id": 4}, {"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_get_probes_results[test_case0]", "teardown": {"duration": 0.00028395652770996094, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.0003628730773925781, "outcome": "skipped", "name": "setup", "longrepr": "('/Users/dbarroso/.virtualenvs/napalm/lib/python2.7/site-packages/_pytest/python.py', 1419, u'Skipped: got empty parameter set, function test_get_probes_results at /Users/dbarroso/workspace/napalm/napalm-base/napalm_base/test/getters.py:52')"}, "run_index": 21, "duration": 0.0010097026824951172, "outcome": "skipped"}, "type": "test", "id": 5}, {"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_get_ntp_stats[normal]", "teardown": {"duration": 0.000102996826171875, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.00035691261291503906, "outcome": "passed", "name": "setup"}, "run_index": 4, "call": {"duration": 0.00020003318786621094, "outcome": "failed", "name": "call", "longrepr": "cls = <test_getters.TestGetter instance at 0x1053a7c20>, test_case = 'normal'\n\n    @functools.wraps(func)\n    def wrapper(cls, test_case):\n        cls.device.device.current_test = func.__name__\n        cls.device.device.current_test_case = test_case\n    \n        try:\n>           result = func(cls)\n\n../napalm-base/napalm_base/test/getters.py:59: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n../napalm-base/napalm_base/test/getters.py:250: in test_get_ntp_stats\n    get_ntp_stats = self.device.get_ntp_stats()\nnapalm_eos/eos.py:832: in get_ntp_stats\n    ntp_assoc = self.device.run_commands(commands, encoding = 'text')[0].get('output', '\\n\\n')\ntest/unit/conftest.py:38: in run_commands\n    full_path = self.find_file(filename)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <conftest.FakeEOSDevice instance at 0x1051718c0>, filename = 'show_ntp_associations.text'\n\n    def find_file(self, filename):\n        \"\"\"Find the necessary file for the given test case.\"\"\"\n        # Find base_dir of submodule\n        module_dir = os.path.dirname(sys.modules[self.__module__].__file__)\n    \n        full_path = os.path.join(module_dir, 'mocked_data',\n                                 self.current_test, self.current_test_case, filename)\n    \n        if os.path.exists(full_path):\n            return full_path\n        else:\n>           raise IOError(\"Couldn't find file with mocked data: {}\".format(full_path))\nE           IOError: Couldn't find file with mocked data: /Users/dbarroso/workspace/napalm/napalm-eos/test/unit/mocked_data/test_get_ntp_stats/normal/show_ntp_associations.text\n\n../napalm-base/napalm_base/test/double.py:28: IOError"}, "duration": 0.001016855239868164, "outcome": "failed"}, "type": "test", "id": 6}, {"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_get_route_to[normal]", "teardown": {"duration": 5.698204040527344e-05, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.0002880096435546875, "outcome": "passed", "name": "setup"}, "run_index": 17, "call": {"duration": 0.0009629726409912109, "outcome": "passed", "name": "call"}, "duration": 0.0015959739685058594, "outcome": "passed"}, "type": "test", "id": 7}, {"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_get_interfaces_counters[normal]", "teardown": {"duration": 6.699562072753906e-05, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.0002560615539550781, "outcome": "passed", "name": "setup"}, "run_index": 14, "call": {"duration": 0.0012290477752685547, "outcome": "passed", "name": "call"}, "duration": 0.00180816650390625, "outcome": "passed"}, "type": "test", "id": 8}, {"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_get_ntp_peers[normal]", "teardown": {"duration": 5.602836608886719e-05, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.00026798248291015625, "outcome": "passed", "name": "setup"}, "run_index": 13, "call": {"duration": 0.001374959945678711, "outcome": "passed", "name": "call"}, "duration": 0.0019669532775878906, "outcome": "passed"}, "type": "test", "id": 9}, {"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_get_environment[normal]", "teardown": {"duration": 6.103515625e-05, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.0002999305725097656, "outcome": "passed", "name": "setup"}, "run_index": 10, "call": {"duration": 0.0042841434478759766, "outcome": "failed", "name": "call", "longrepr": "cls = <test_getters.TestGetter instance at 0x1054ddb90>, test_case = 'normal'\n\n    @functools.wraps(func)\n    def wrapper(cls, test_case):\n        cls.device.device.current_test = func.__name__\n        cls.device.device.current_test_case = test_case\n    \n        try:\n            result = func(cls)\n            not_implemented = False\n    \n            if isinstance(cls.device.device, BaseTestDouble):\n                if isinstance(result, list):\n                    diff = list_dicts_diff(result, cls.device.device.expected_result)\n                else:\n                    diff = dict_diff(result, cls.device.device.expected_result)\n                if diff:\n                    print(\"Resulting JSON object was: {}\".format(json.dumps(result)))\n>                   raise AssertionError(\"Expected result varies on some keys {}\".format(diff))\nE                   AssertionError: Expected result varies on some keys {'cpu': {0: {'expected': None, 'result': {'%usage': 3.5}}, u'0': {'expected': {u'%usage': 3.5}, 'result': None}}}\n\n../napalm-base/napalm_base/test/getters.py:69: AssertionError"}, "duration": 0.004945039749145508, "outcome": "failed"}, "type": "test", "id": 10}, {"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_get_arp_table[normal]", "teardown": {"duration": 6.29425048828125e-05, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.0002608299255371094, "outcome": "passed", "name": "setup"}, "run_index": 12, "call": {"duration": 0.0005860328674316406, "outcome": "passed", "name": "call"}, "duration": 0.0011706352233886719, "outcome": "passed"}, "type": "test", "id": 11}, {"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_get_probes_config[test_case0]", "teardown": {"duration": 6.079673767089844e-05, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.00021791458129882812, "outcome": "skipped", "name": "setup", "longrepr": "('/Users/dbarroso/.virtualenvs/napalm/lib/python2.7/site-packages/_pytest/python.py', 1419, u'Skipped: got empty parameter set, function test_get_probes_config at /Users/dbarroso/workspace/napalm/napalm-base/napalm_base/test/getters.py:52')"}, "run_index": 1, "duration": 0.0004966259002685547, "outcome": "skipped"}, "type": "test", "id": 12}, {"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_get_users[normal]", "teardown": {"duration": 8.487701416015625e-05, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.00032901763916015625, "outcome": "passed", "name": "setup"}, "run_index": 8, "call": {"duration": 0.0024662017822265625, "outcome": "failed", "name": "call", "longrepr": "cls = <test_getters.TestGetter instance at 0x1051a3950>, test_case = 'normal'\n\n    @functools.wraps(func)\n    def wrapper(cls, test_case):\n        cls.device.device.current_test = func.__name__\n        cls.device.device.current_test_case = test_case\n    \n        try:\n            result = func(cls)\n            not_implemented = False\n    \n            if isinstance(cls.device.device, BaseTestDouble):\n                if isinstance(result, list):\n                    diff = list_dicts_diff(result, cls.device.device.expected_result)\n                else:\n>                   diff = dict_diff(result, cls.device.device.expected_result)\n\n../napalm-base/napalm_base/test/getters.py:66: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n../napalm-base/napalm_base/test/double.py:51: in expected_result\n    filename = self.find_file('expected_result.json')\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <conftest.FakeEOSDevice instance at 0x1051718c0>, filename = 'expected_result.json'\n\n    def find_file(self, filename):\n        \"\"\"Find the necessary file for the given test case.\"\"\"\n        # Find base_dir of submodule\n        module_dir = os.path.dirname(sys.modules[self.__module__].__file__)\n    \n        full_path = os.path.join(module_dir, 'mocked_data',\n                                 self.current_test, self.current_test_case, filename)\n    \n        if os.path.exists(full_path):\n            return full_path\n        else:\n>           raise IOError(\"Couldn't find file with mocked data: {}\".format(full_path))\nE           IOError: Couldn't find file with mocked data: /Users/dbarroso/workspace/napalm/napalm-eos/test/unit/mocked_data/test_get_users/normal/expected_result.json\n\n../napalm-base/napalm_base/test/double.py:28: IOError"}, "duration": 0.0032091140747070312, "outcome": "failed"}, "type": "test", "id": 13}, {"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_ping[test_case0]", "teardown": {"duration": 4.982948303222656e-05, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.00020694732666015625, "outcome": "skipped", "name": "setup", "longrepr": "('/Users/dbarroso/.virtualenvs/napalm/lib/python2.7/site-packages/_pytest/python.py', 1419, u'Skipped: got empty parameter set, function test_ping at /Users/dbarroso/workspace/napalm/napalm-base/napalm_base/test/getters.py:52')"}, "run_index": 19, "duration": 0.00046372413635253906, "outcome": "skipped"}, "type": "test", "id": 14}, {"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_get_bgp_config[normal]", "teardown": {"duration": 7.700920104980469e-05, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.0002779960632324219, "outcome": "passed", "name": "setup"}, "run_index": 7, "call": {"duration": 0.0001990795135498047, "outcome": "failed", "name": "call", "longrepr": "cls = <test_getters.TestGetter instance at 0x10512dcb0>, test_case = 'normal'\n\n    @functools.wraps(func)\n    def wrapper(cls, test_case):\n        cls.device.device.current_test = func.__name__\n        cls.device.device.current_test_case = test_case\n    \n        try:\n>           result = func(cls)\n\n../napalm-base/napalm_base/test/getters.py:59: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n../napalm-base/napalm_base/test/getters.py:194: in test_get_bgp_config\n    get_bgp_config = self.device.get_bgp_config()\nnapalm_eos/eos.py:670: in get_bgp_config\n    bgp_conf = self.device.run_commands(commands, encoding='text')[0].get('output', '\\n\\n')\ntest/unit/conftest.py:38: in run_commands\n    full_path = self.find_file(filename)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <conftest.FakeEOSDevice instance at 0x1051718c0>, filename = 'show_running-config___section_router_bgp.text'\n\n    def find_file(self, filename):\n        \"\"\"Find the necessary file for the given test case.\"\"\"\n        # Find base_dir of submodule\n        module_dir = os.path.dirname(sys.modules[self.__module__].__file__)\n    \n        full_path = os.path.join(module_dir, 'mocked_data',\n                                 self.current_test, self.current_test_case, filename)\n    \n        if os.path.exists(full_path):\n            return full_path\n        else:\n>           raise IOError(\"Couldn't find file with mocked data: {}\".format(full_path))\nE           IOError: Couldn't find file with mocked data: /Users/dbarroso/workspace/napalm/napalm-eos/test/unit/mocked_data/test_get_bgp_config/normal/show_running-config___section_router_bgp.text\n\n../napalm-base/napalm_base/test/double.py:28: IOError"}, "duration": 0.0008320808410644531, "outcome": "failed"}, "type": "test", "id": 15}, {"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_get_interfaces[normal]", "teardown": {"duration": 8.511543273925781e-05, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.014241933822631836, "outcome": "passed", "name": "setup"}, "run_index": 0, "call": {"duration": 0.0010221004486083984, "outcome": "passed", "name": "call"}, "duration": 0.029591083526611328, "outcome": "passed"}, "type": "test", "id": 16}, {"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_get_snmp_information[normal]", "teardown": {"duration": 6.103515625e-05, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.0002989768981933594, "outcome": "passed", "name": "setup"}, "run_index": 11, "call": {"duration": 0.0031731128692626953, "outcome": "passed", "name": "call"}, "duration": 0.003832101821899414, "outcome": "passed"}, "type": "test", "id": 17}, {"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_traceroute[normal]", "teardown": {"duration": 7.987022399902344e-05, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.0005710124969482422, "outcome": "passed", "name": "setup"}, "run_index": 9, "call": {"duration": 0.005758047103881836, "outcome": "failed", "name": "call", "longrepr": "cls = <test_getters.TestGetter instance at 0x1053153b0>, test_case = 'normal'\n\n    @functools.wraps(func)\n    def wrapper(cls, test_case):\n        cls.device.device.current_test = func.__name__\n        cls.device.device.current_test_case = test_case\n    \n        try:\n            result = func(cls)\n            not_implemented = False\n    \n            if isinstance(cls.device.device, BaseTestDouble):\n                if isinstance(result, list):\n                    diff = list_dicts_diff(result, cls.device.device.expected_result)\n                else:\n                    diff = dict_diff(result, cls.device.device.expected_result)\n                if diff:\n                    print(\"Resulting JSON object was: {}\".format(json.dumps(result)))\n>                   raise AssertionError(\"Expected result varies on some keys {}\".format(diff))\nE                   AssertionError: Expected result varies on some keys {'success': {1: {'expected': None, 'result': {'probes': {1: {'rtt': 0.985, 'ip_address': u'1.1.1.1', 'host_name': u'rcr2.bru01.atlas.cogentco.com'}, 2: {'rtt': 1.278, 'ip_address': u'1.1.1.1', 'host_name': u'rcr2.bru01.atlas.cogentco.com'}, 3: {'rtt': 1.347, 'ip_address': u'1.1.1.1', 'host_name': u'rcr2.bru01.atlas.cogentco.com'}}}}, 2: {'expected': None, 'result': {'probes': {1: {'rtt': 6.6, 'ip_address': u'2.2.2.2', 'host_name': u'ccr1.par01.atlas.cogentco.com'}, 2: {'rtt': 6.514, 'ip_address': u'2.2.2.3', 'host_name': u'ccr00.par01.atlas.cogentco.com'}, 3: {'rtt': 6.438, 'ip_address': u'2.2.2.3', 'host_name': u'ccr00.par01.atlas.cogentco.com'}}}}, 3: {'expected': None, 'result': {'probes': {1: {'rtt': 6.477, 'ip_address': u'3.3.3.3', 'host_name': u'ccr1.par04.atlas.cogentco.com'}, 2: {'rtt': 6.932, 'ip_address': u'3.3.3.4', 'host_name': u'ccr00.par04.atlas.cogentco.com'}, 3: {'rtt': 6.914, 'ip_address': u'3.3.3.4', 'host_name': u'ccr00.par04.atlas.cogentco.com'}}}}, 4: {'expected': None, 'result': {'probes': {1: {'rtt': 6.356, 'ip_address': u'4.4.4.4', 'host_name': u'par57.atlas.cogentco.com'}, 2: {'rtt': 6.413, 'ip_address': u'4.4.4.4', 'host_name': u'par57.atlas.cogentco.com'}, 3: {'rtt': 6.406, 'ip_address': u'4.4.4.4', 'host_name': u'par57.atlas.cogentco.com'}}}}, 5: {'expected': None, 'result': {'probes': {1: {'rtt': 14.402, 'ip_address': u'5.5.5.5', 'host_name': u'5.5.5.5'}, 2: {'rtt': 14.398, 'ip_address': u'5.5.5.5', 'host_name': u'5.5.5.5'}, 3: {'rtt': 14.373, 'ip_address': u'5.5.5.5', 'host_name': u'5.5.5.5'}}}}, 6: {'expected': None, 'result': {'probes': {1: {'rtt': 15.083, 'ip_address': u'6.6.6.6', 'host_name': u'6.6.6.6'}, 2: {'rtt': 15.104, 'ip_address': u'6.6.6.6', 'host_name': u'6.6.6.6'}, 3: {'rtt': 14.691, 'ip_address': u'6.6.6.7', 'host_name': u'6.6.6.7'}}}}, 7: {'expected': None, 'result': {'probes': {1: {'rtt': 14.886, 'ip_address': u'7.7.7.7', 'host_name': u'7.7.7.7'}, 2: {'rtt': 15.258, 'ip_address': u'7.7.7.8', 'host_name': u'7.7.7.8'}, 3: {'rtt': 15.323, 'ip_address': u'7.7.7.8', 'host_name': u'7.7.7.9'}}}}, 8: {'expected': None, 'result': {'probes': {1: {'rtt': 5000.0, 'ip_address': u'*', 'host_name': u'*'}, 2: {'rtt': 5000.0, 'ip_address': u'*', 'host_name': u'*'}, 3: {'rtt': 5000.0, 'ip_address': u'*', 'host_name': u'*'}}}}, 9: {'expected': None, 'result': {'probes': {1: {'rtt': 15.561, 'ip_address': u'8.8.8.8', 'host_name': u'google-public-dns-a.google.com'}, 2: {'rtt': 14.686, 'ip_address': u'8.8.8.8', 'host_name': u'google-public-dns-a.google.com'}, 3: {'rtt': 14.32, 'ip_address': u'8.8.8.8', 'host_name': u'google-public-dns-a.google.com'}}}}, u'1': {'expected': {u'probes': {u'1': {u'rtt': 0.985, u'ip_address': u'1.1.1.1', u'host_name': u'rcr2.bru01.atlas.cogentco.com'}, u'3': {u'rtt': 1.347, u'ip_address': u'1.1.1.1', u'host_name': u'rcr2.bru01.atlas.cogentco.com'}, u'2': {u'rtt': 1.278, u'ip_address': u'1.1.1.1', u'host_name': u'rcr2.bru01.atlas.cogentco.com'}}}, 'result': None}, u'3': {'expected': {u'probes': {u'1': {u'rtt': 6.477, u'ip_address': u'3.3.3.3', u'host_name': u'ccr1.par04.atlas.cogentco.com'}, u'3': {u'rtt': 6.914, u'ip_address': u'3.3.3.4', u'host_name': u'ccr00.par04.atlas.cogentco.com'}, u'2': {u'rtt': 6.932, u'ip_address': u'3.3.3.4', u'host_name': u'ccr00.par04.atlas.cogentco.com'}}}, 'result': None}, u'2': {'expected': {u'probes': {u'1': {u'rtt': 6.6, u'ip_address': u'2.2.2.2', u'host_name': u'ccr1.par01.atlas.cogentco.com'}, u'3': {u'rtt': 6.438, u'ip_address': u'2.2.2.3', u'host_name': u'ccr00.par01.atlas.cogentco.com'}, u'2': {u'rtt': 6.514, u'ip_address': u'2.2.2.3', u'host_name': u'ccr00.par01.atlas.cogentco.com'}}}, 'result': None}, u'5': {'expected': {u'probes': {u'1': {u'rtt': 14.402, u'ip_address': u'5.5.5.5', u'host_name': u'5.5.5.5'}, u'3': {u'rtt': 14.373, u'ip_address': u'5.5.5.5', u'host_name': u'5.5.5.5'}, u'2': {u'rtt': 14.398, u'ip_address': u'5.5.5.5', u'host_name': u'5.5.5.5'}}}, 'result': None}, u'4': {'expected': {u'probes': {u'1': {u'rtt': 6.356, u'ip_address': u'4.4.4.4', u'host_name': u'par57.atlas.cogentco.com'}, u'3': {u'rtt': 6.406, u'ip_address': u'4.4.4.4', u'host_name': u'par57.atlas.cogentco.com'}, u'2': {u'rtt': 6.413, u'ip_address': u'4.4.4.4', u'host_name': u'par57.atlas.cogentco.com'}}}, 'result': None}, u'7': {'expected': {u'probes': {u'1': {u'rtt': 14.886, u'ip_address': u'7.7.7.7', u'host_name': u'7.7.7.7'}, u'3': {u'rtt': 15.323, u'ip_address': u'7.7.7.8', u'host_name': u'7.7.7.9'}, u'2': {u'rtt': 15.258, u'ip_address': u'7.7.7.8', u'host_name': u'7.7.7.8'}}}, 'result': None}, u'6': {'expected': {u'probes': {u'1': {u'rtt': 15.083, u'ip_address': u'6.6.6.6', u'host_name': u'6.6.6.6'}, u'3': {u'rtt': 14.691, u'ip_address': u'6.6.6.7', u'host_name': u'6.6.6.7'}, u'2': {u'rtt': 15.104, u'ip_address': u'6.6.6.6', u'host_name': u'6.6.6.6'}}}, 'result': None}, u'9': {'expected': {u'probes': {u'1': {u'rtt': 15.561, u'ip_address': u'8.8.8.8', u'host_name': u'google-public-dns-a.google.com'}, u'3': {u'rtt': 14.32, u'ip_address': u'8.8.8.8', u'host_name': u'google-public-dns-a.google.com'}, u'2': {u'rtt': 14.686, u'ip_address': u'8.8.8.8', u'host_name': u'google-public-dns-a.google.com'}}}, 'result': None}, u'8': {'expected': {u'probes': {u'1': {u'rtt': 5000.0, u'ip_address': u'*', u'host_name': u'*'}, u'3': {u'rtt': 5000.0, u'ip_address': u'*', u'host_name': u'*'}, u'2': {u'rtt': 5000.0, u'ip_address': u'*', u'host_name': u'*'}}}, 'result': None}}}\n\n../napalm-base/napalm_base/test/getters.py:69: AssertionError"}, "duration": 0.006979942321777344, "outcome": "failed"}, "type": "test", "id": 18}, {"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_get_bgp_neighbors_detail[test_case0]", "teardown": {"duration": 5.0067901611328125e-05, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.00019097328186035156, "outcome": "skipped", "name": "setup", "longrepr": "('/Users/dbarroso/.virtualenvs/napalm/lib/python2.7/site-packages/_pytest/python.py', 1419, u'Skipped: got empty parameter set, function test_get_bgp_neighbors_detail at /Users/dbarroso/workspace/napalm/napalm-base/napalm_base/test/getters.py:52')"}, "run_index": 6, "duration": 0.00043201446533203125, "outcome": "skipped"}, "type": "test", "id": 19}, {"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_get_lldp_neighbors[normal]", "teardown": {"duration": 8.296966552734375e-05, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.0003230571746826172, "outcome": "passed", "name": "setup"}, "run_index": 3, "call": {"duration": 0.0024428367614746094, "outcome": "failed", "name": "call", "longrepr": "cls = <test_getters.TestGetter instance at 0x105136128>, test_case = 'normal'\n\n    @functools.wraps(func)\n    def wrapper(cls, test_case):\n        cls.device.device.current_test = func.__name__\n        cls.device.device.current_test_case = test_case\n    \n        try:\n            result = func(cls)\n            not_implemented = False\n    \n            if isinstance(cls.device.device, BaseTestDouble):\n                if isinstance(result, list):\n                    diff = list_dicts_diff(result, cls.device.device.expected_result)\n                else:\n>                   diff = dict_diff(result, cls.device.device.expected_result)\n\n../napalm-base/napalm_base/test/getters.py:66: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n../napalm-base/napalm_base/test/double.py:51: in expected_result\n    filename = self.find_file('expected_result.json')\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <conftest.FakeEOSDevice instance at 0x1051718c0>, filename = 'expected_result.json'\n\n    def find_file(self, filename):\n        \"\"\"Find the necessary file for the given test case.\"\"\"\n        # Find base_dir of submodule\n        module_dir = os.path.dirname(sys.modules[self.__module__].__file__)\n    \n        full_path = os.path.join(module_dir, 'mocked_data',\n                                 self.current_test, self.current_test_case, filename)\n    \n        if os.path.exists(full_path):\n            return full_path\n        else:\n>           raise IOError(\"Couldn't find file with mocked data: {}\".format(full_path))\nE           IOError: Couldn't find file with mocked data: /Users/dbarroso/workspace/napalm/napalm-eos/test/unit/mocked_data/test_get_lldp_neighbors/normal/expected_result.json\n\n../napalm-base/napalm_base/test/double.py:28: IOError"}, "duration": 0.0031719207763671875, "outcome": "failed"}, "type": "test", "id": 20}, {"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_get_facts[normal]", "teardown": {"duration": 6.890296936035156e-05, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.0003559589385986328, "outcome": "passed", "name": "setup"}, "run_index": 5, "call": {"duration": 0.002077817916870117, "outcome": "passed", "name": "call"}, "duration": 0.0028586387634277344, "outcome": "passed"}, "type": "test", "id": 21}, {"attributes": {"name": "test/unit/test_getters.py::TestGetter::()::test_get_mac_address_table[normal]", "teardown": {"duration": 6.103515625e-05, "outcome": "passed", "name": "teardown"}, "setup": {"duration": 0.00024580955505371094, "outcome": "passed", "name": "setup"}, "run_index": 16, "call": {"duration": 0.002936124801635742, "outcome": "passed", "name": "call"}, "duration": 0.003488779067993164, "outcome": "passed"}, "type": "test", "id": 22}], "data": [{"relationships": {"tests": {"data": [{"type": "test", "id": 1}, {"type": "test", "id": 2}, {"type": "test", "id": 3}, {"type": "test", "id": 4}, {"type": "test", "id": 5}, {"type": "test", "id": 6}, {"type": "test", "id": 7}, {"type": "test", "id": 8}, {"type": "test", "id": 9}, {"type": "test", "id": 10}, {"type": "test", "id": 11}, {"type": "test", "id": 12}, {"type": "test", "id": 13}, {"type": "test", "id": 14}, {"type": "test", "id": 15}, {"type": "test", "id": 16}, {"type": "test", "id": 17}, {"type": "test", "id": 18}, {"type": "test", "id": 19}, {"type": "test", "id": 20}, {"type": "test", "id": 21}, {"type": "test", "id": 22}]}}, "attributes": {"environment": {"Python": "2.7.11", "Platform": "Darwin-15.5.0-x86_64-i386-64bit"}, "created_at": "2016-07-26 14:22:10.759785", "summary": {"duration": 1.0842018127441406, "failed": 7, "skipped": 5, "passed": 10, "num_tests": 22}}, "type": "report", "id": 1}]}